{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s71h1bcdVaCb",
        "outputId": "23d859ca-dc38-4e34-90b0-b5cffa9d4bf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched Article: Perspective | Gross and embarrassing — teen girls’ misconceptions about their periods - The Washington Post Parents can help dispel confusion and misinformation and alleviate the anxiety and shame some girls may feel about menstruation.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "def fetch_news_article(api_key):\n",
        "    url = f'https://newsapi.org/v2/top-headlines?country=us&apiKey={api_key}'\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "    if data['status'] == 'ok' and data['articles']:\n",
        "        articles = data['articles']\n",
        "        for article in articles:\n",
        "            if article['title'] and article['description']:\n",
        "                return article['title'] + \" \" + article['description']\n",
        "    return None\n",
        "\n",
        "api_key = '6147612c50e44dc2a3b6ba5204ff1179'  # Replace with your actual API key\n",
        "article = fetch_news_article(api_key)\n",
        "if article:\n",
        "    print(\"Fetched Article:\", article)\n",
        "else:\n",
        "    print(\"Failed to fetch an article. Please check your API key and network connection.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('averaged_perceptron_tagger')  # Added this line\n",
        "\n",
        "def nltk_ner(text):\n",
        "    words = word_tokenize(text)\n",
        "    tags = pos_tag(words)\n",
        "    tree = ne_chunk(tags)\n",
        "    entities = []\n",
        "    for subtree in tree:\n",
        "        if isinstance(subtree, nltk.Tree):\n",
        "            entity = \" \".join([word for word, tag in subtree.leaves()])\n",
        "            entity_type = subtree.label()\n",
        "            entities.append((entity, entity_type))\n",
        "    return entities\n",
        "\n",
        "if article:\n",
        "    nltk_entities = nltk_ner(article)\n",
        "    print(\"NLTK Entities:\", nltk_entities)\n",
        "else:\n",
        "    print(\"No article to process.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sjAMgoNVfLx",
        "outputId": "df27dc8a-c2ae-4991-a6d5-0e02d5bf2fce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Entities: [('Washington Post Parents', 'ORGANIZATION')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def spacy_ner(text):\n",
        "    doc = nlp(text)\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return entities\n",
        "\n",
        "if article:\n",
        "    spacy_entities = spacy_ner(article)\n",
        "    print(\"SpaCy Entities:\", spacy_entities)\n",
        "else:\n",
        "    print(\"No article to process.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSmovq5AW3Q2",
        "outputId": "fa56a7e1-595e-4867-db12-7368bdf6c621"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SpaCy Entities: [('Gross', 'PERSON'), ('The Washington Post Parents', 'ORG')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_entities(nltk_entities, spacy_entities):\n",
        "    nltk_set = set(nltk_entities)\n",
        "    spacy_set = set(spacy_entities)\n",
        "\n",
        "    common = nltk_set & spacy_set\n",
        "    only_nltk = nltk_set - spacy_set\n",
        "    only_spacy = spacy_set - nltk_set\n",
        "\n",
        "    return common, only_nltk, only_spacy\n",
        "\n",
        "if article:\n",
        "    common_entities, only_nltk_entities, only_spacy_entities = compare_entities(nltk_entities, spacy_entities)\n",
        "\n",
        "    print(\"Common Entities:\", common_entities)\n",
        "    print(\"Entities only in NLTK:\", only_nltk_entities)\n",
        "    print(\"Entities only in SpaCy:\", only_spacy_entities)\n",
        "else:\n",
        "    print(\"No entities to compare.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcvKnVLpW_Fi",
        "outputId": "cef85960-2cc4-491c-e3f1-f9147e79755c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common Entities: set()\n",
            "Entities only in NLTK: {('Washington Post Parents', 'ORGANIZATION')}\n",
            "Entities only in SpaCy: {('Gross', 'PERSON'), ('The Washington Post Parents', 'ORG')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c1dk2swZXEGr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}